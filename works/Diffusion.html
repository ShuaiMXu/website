<!DOCTYPE html>
<html dir="ltr" lang="en-US">

<head>

	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta content="IE=edge" http-equiv="X-UA-Compatible">
	<meta content="width=device-width,initial-scale=1" name="viewport">
	<meta name="author" content="Shuai Xu" />

	<!-- Stylesheets
	============================================= -->
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,400i,700|Raleway:300,400,500,600,700|Crete+Round:400i" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" href="../assets/css/bootstrap.css" type="text/css" />
	<link rel="stylesheet" href="../style.css" type="text/css" />
	<link rel="stylesheet" href="../assets/css/dark.css" type="text/css" />
	<link rel="stylesheet" href="../assets/css/font-icons.css" type="text/css" />
	<link rel="stylesheet" href="../assets/css/animate.css" type="text/css" />
	<link rel="stylesheet" href="../assets/css/magnific-popup.css" type="text/css" />
	<link rel="stylesheet" href="../assets/css/color.css" type="text/css" />
	<link rel="stylesheet" href="../assets/css/responsive.css" type="text/css" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<link rel="stylesheet" href="../assets/css/responsive.css" type="text/css" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />

	<!-- Document Title
	============================================= -->
	<title>Diffusion | ShuaiMXU</title>

</head>

<body class="stretched">

	<!-- Document Wrapper
	============================================= -->
	<div id="wrapper" class="clearfix">

		<!-- Header
  ============================================= -->
		<header id="header" class="transparent-header" data-sticky-class="dark">

			<div id="header-wrap">

				<div class="container clearfix">

					<div id="primary-menu-trigger"><i class="icon-reorder"></i></div>
					<!-- Primary Navigation
      ============================================= -->
					<nav id="primary-menu" class="dark" class="mobile-primary-menu">
						<ul>
							<li class="current"><a href="../index.html">
									<div>Home</div>
								</a>
						</ul>
						<ul>
							<li class="current"><a href="portfolio-main.html">
									<div>Portfolio</div>
								</a>
						</ul>
						<ul>
							<li class="current"><a href="../photograph/photograph.html">
									<div>Photograph</div>
								</a>
						</ul>
						<ul>
							<li class="current"><a href="../about/about.html">
									<div> About me</div>
								</a>
						</ul>
					</nav><!-- #primary-menu end -->
				</div>
			</div>
		</header> <!-- #header end -->

		<!-- Page Title
		============================================= -->
		<section id="page-title">

			<div class="container clearfix">
				<h1>Diffusion</h1>
			</div>

		</section><!-- #page-title end -->

		<!-- Content
		============================================= -->
		<!-- Content
		============================================= -->
		<section id="content">

			<div class="content-wrap">

				<div class="container clearfix">

					<div class="single-post nobottommargin">
						<!-- Post Content
					============================================= -->


						<!-- Portfolio Single Video
							============================================= -->
						<div class="entry-image">
							<iframe width="560" height="315" src="https://www.youtube.com/embed/wEwM5AXlxx0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>

						<!-- Entry Content
								============================================= -->
						<div class="entry-content notopmargin">

							<h2></h2>
							<p> "Diffusion" is a performance (Interactive installation) that uses a brainwave sensor (EEG) to convert the intangible abstraction brain activity, thinking, or feeling into tangible things such as sounds, objects, sculptures.</p>

							<p> As well as using this interactive project in connection with human brain activity, it will unleash the inherent meaning between thought and matter, concept and object, human and machine.</p>
							<P> Performer: Dahong Wang, Yuhao Yin, Meijun Xu </P>
						</div>

						<!-- Portfolio Single Gallery
						============================================= -->
						<!-- Portfolio Single Gallery Thumbs
						============================================= -->
						<div class="col_full portfolio-single-image masonry-thumbs grid-4" data-big="3" data-lightbox="gallery">
							<!-- <a href="../images/Diffusion.gif" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion.gif" alt="Gallery Thumb 1"></a> -->
							<a href="../images/Diffusion/1.jpeg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/1.jpeg" alt="Gallery Thumb 1"></a>
							<a href="../images/Diffusion/2.jpeg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/2.jpeg" alt="Gallery Thumb 2"></a>
							<a href="../images/Diffusion/3.jpeg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/3.jpeg" alt="Gallery Thumb 3"></a>
							<a href="../images/Diffusion/4.jpeg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/4.jpeg" alt="Gallery Thumb 4"></a>
							<a href="../images/Diffusion/5.jpeg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/5.jpeg" alt="Gallery Thumb 5"></a>
							<!-- <a href="../images/chaos/chao8.jpg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/chao8.jpg" alt="Gallery Thumb 8"></a>
							<a href="../images/chaos/chao2.jpg" data-lightbox="gallery-item"><img class="image_fade" src="../images/Diffusion/chao2.jpg" alt="Gallery Thumb 9"></a> -->
						</div>
						<!-- .portfolio-single-image end -->
						<div class="entry-content notopmargin">

							<h3><strong>Introduction</strong></h3>
							<p>This research seeks to investigate the intertwined and interactive relationship between human consciousness and computational practise through an analysis of human brain data from an electroencephalogram based on Brain-Computer
								Interfaces and an interactive installation. For this project, through phenomenological research, human consciousness becomes a medium of expression and creation and enhances the embodiment and sensation of the emotion through tangible
								and intangible feelings. As a result, this project is an experiment intended to convert intangible abstraction brain activity (thinking or feeling) into tangible things, such as sounds, objects or sculptures.</p>

							<p><strong>Keywords: EEG, brain activity, visual stimuli, smart material, Max/MSP, physical computing, interactive installation, biosensor</strong></p>

							<h3><strong>Research Questions </strong></h3>
							<p>This research project aims to analyse both sides of the interaction, especially concerning the relationship between human brain activity, biofeedback and a brain worker's sense of presence. Here, two questions are proposed to guide
								the deep consideration of this experiment:</p>
							<p>1. How can we create a bridge that interacts between brain activity and audio-visual installation during interactive experiences?</p>
							<p>2. How does audio-visual stimulus variation alter an individual's state of human brain activity? How do they influence each other?</p>
							<p>This project explores these questions through three aspects. Firstly, relevant theory and practise in the contemporary art field of Electroencephalography (EEG) will be presented, with a discussion on 'human-made' (artificial) and a
								description of how a narrative is created using a biosensor. Secondly, this essay will explain how the audio component of this interactive installation makes generative music from the biofeedback produced by the EEG and what kinds of
								technology may apply. Thirdly, this essay shall present the relationship between humans and machines. Finally, and most importantly, this essay will explain the audio-visual installation of diffusion and demonstrate how one may
								perform an interactive performance and a process of 'human-made'.</p>
						</div>

						<h3><strong>Concept and background research</strong></h3>
						<p>As Benayoun states in ‘AI, all too Human’ (2017), the term 'human-made’ refers to human development. It can be found in western epic records and eastern epic records; humans have been creating new ideas throughout history. The story of
							artificial intelligence (AI) started with humans wanting to invent a new form of manufacturing. For example, AI subtly helps us improve our quality of life and to control or trigger evolution. AI gives us a chance to know nearly
							everything. We can learn or control everything, we can create a cycle or let a machine produce another machine. Nowadays, we can deal with most daily tasks, such as designing or moving objects. Most jobs are automatically completed. In
							this case, human-made becomes a natural phenomenon; we do not even notice it.</p>
						<p>This project, ‘Diffusion’ will help us understand or feel what human-made (artificial) is, things that we do not pay attention to or notice. Exhibition participants will control some real thing such as sounds, visual system, and
							ferrofluid by using their brain activity, which can be though thinking, feeling or meditation. During the process, to understand the real human-made, real artificial; I cannot explain it, because human consciousness is becoming more and
							more impenetrable, perhaps only intelligence can understand human-made (artificial).</p>

						<div class="entry-image">
							<a href="../images/Diffusion/6.png" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/6.png" alt="Standard Post with Image"></a>
						</div>
						<h3><strong>The installation</strong></h3>
						<h4><strong>Generative Music</strong></h4>
						<p>To gain the brainwave data from participants, the ‘Muse2’ EEG headset was selected. This is a good EEG headset for primary research to receive brain waves. This sensor can facilitate four channels of EEG data, which separately
							correspond with four parts of the brain (left ear, left forehead, right ear, right forehead). Max/MSP software was used to build the music system for obtaining an artistic music intention. The Max/MSP patch is built upon four main
							elements: the data input from the EEG sensor, the leading music generator, sound effects, and music filters. Max/MSP includes lowpass, bandpass, highpass and a distorted and transformed audio output.</p>
						<div class="entry-image">
							<a href="../images/Diffusion/7.png" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/7.png" alt="Standard Post with Image"></a>
						</div>
						<div class="entry-image">
							<a href="../images/Diffusion/8.png" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/8.png" alt="Standard Post with Image"></a>
						</div>
						<div class="entry-image">
							<a href="../images/Diffusion/9.png" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/9.png" alt="Standard Post with Image"></a>
						</div>
						<h4><strong>Machine learning</strong></h4>
						<p>This project uses machine learning as a tool for analysing EEG data and musical elements. I used Max/MSP as a bridge to receive EEG data and send it to Wekinator (machine learning software) by Open Sound Control (OSC), and again to
							collect the training data to make the music.</p>
						<p>The EEG sensor, 'Muse2', provided four EEG data channels; it is the original signal about brain activity; The experimental proof that the original signals are no rules at all, which only shows the feedback of electrodes on the
							performer's head. As a result, in order to gain more easily controlled data, I sent all the raw data to Wekinator for pre-processing. In Wekinator, the four channels of data were processed separately by linear regression.</p>
						<div class="entry-image">
							<a href="../images/Diffusion/10.png" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/10.png" alt="Standard Post with Image"></a>
						</div>
						<h4><strong>Physical Interactive installation</strong></h4>
						<p>To mimic the brain behaviour, this experiment attempts to forge a relationship between brain activity and ferrofluid. The four channels of EEG data will be the primary input and will control this installation. This installation has
							three working progress stages: (1) Exploration of material, (2) interaction in the project and (3) final presentation.</p>
						<p>The first stage of this project was aimed at exploring the dynamic movement of the magnetic fluid. This was a simple experiment. I tried different methods to control the ferrofluid and the various materials of magnetic fluid. The most
							satisfactory result was the ferrofluid in the aqueous or oily environment.</p>
						<div class="entry-image">
							<a href="../images/Diffusion/11.gif" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/11.gif" alt="Standard Post with Image"></a>
						</div>
						<p>In the second stage, I built a simple demonstration structure, which included a frame structure, two motors, some wires and an Arduino Uno board. I then sent the EEG data to the Arduino and mapped the EEG data movement and
							angle of the motors. Thus, I could control the range of movement of the motors based on the EEG data.</p>
						<div class="entry-image">
							<a href="../images/Diffusion/12.gif" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/12.gif" alt="Standard Post with Image"></a>
						</div>
						<p>In the final stage, I connected human activity and the ferrofluid installation more directly. I tried to use electromagnets to control the ferrofluid. I accessed the human brainwaves channel to obtain the produced electrical pulses –
							visualise a wave rippling through the crowd at a sports arena. As a result, the brainwaves affect the ferrofluid directly. This is a straightforward way to visualise the intangible brain activity and the movement of ferrofluid will be
							used as a direct way to express the realisation of ‘human-made’.</p>
						<div class="entry-image">
							<a href="../images/Diffusion/13.gif" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/13.gif" alt="Standard Post with Image"></a>
						</div>
						<h4><strong>Visual system</strong></h4>
						<p>Because this project will perform at an immersive space where have multiple projectors and 10 audio channels, so I made a visual system for this project. For this visual system, this main computational software is Max/MSP, using the
							GL3 engine, and shader to making this visual system.</p>
						<div class="entry-image">
							<a href="../images/Diffusion/14.gif" data-lightbox="image"><img class="image_fade" src="../images/Diffusion/14.gif" alt="Standard Post with Image"></a>
						</div>
						<h3><strong>Final Performance</strong></h3>
						<p>Throughout this project, I have utilised human creativity and emotion design within an interactive system, which includes sound, visuals and sculpture. I have achieved this by using EEG sensors to track the performer's brain activity
							to interact with sound, visuals and ferrofluid sculpting. The performance had three performers who had different types of behaviour and bodily movements. The results provided an excellent response to the two research questions. The
							performer served as a satisfactory bridge while connecting to the audio-visual installation. For example, when the performer was calm or meditated, the installation provided an interactive experience; the sound, visual and ferrofluid
							maintained a soft result. Conversely, when the performer did strenuous exercise or thought about various things, the brainwave fluctuated sharply, and the sound, visual system and ferrofluid also changed drastically.</p>
						<p>This project was affected by human brain activity. However, during the performance, the performer is also affected by the environment, the sound and the visual system. These factors potentially influenced the performer into a state of
							relaxation, tension, thought or even anger and reflection. This means that the performer becomes a part of creating the meaning of the performance itself. The performer builds a relationship between the audio-visual and human brain
							activity. They are not autonomous; they supplement each other.</p>
						<div class="entry-image">
							<iframe width="560" height="315" src="https://www.youtube.com/embed/t31GOojyXgM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>
						<h3><strong>Self-evaluation</strong></h3>
						<p>For this project, this is my first time to build a generative music system, first time doing a performance show. I know, my music systems are not enough powerful to generate a variety of sounds. The visual system also makes me feel
							that I am not so excellent in many times, and the physical part also is unsuccessful, It is still a long way from my expectations, so I still need to be studied and do more research about that.</p>
						<h3><strong>Future Research Areas</strong></h3>
						<p>I plan to engage in 'human-made' in future endeavours. I will keep researching EEG sensors and try to use other EEG headsets, such as NeuroSky and OpenBCI. Additionally, I will be expanding my EEG dataset. I want to collect brainwave
							data that reflect different ages and races, which will make the brain feedback more accurate. Once I achieve this, I will enter the next stage, and try to combine a Virtual reality (VR) headset and an EEG sensor, to create a
							storytelling game with these technologies. I intend to show the results of 'human-made' in an immersive environment. Furthermore, I will try to use other biosensors to understand 'human-made' (artificial).</p>
						<h3><strong>Reference</strong></h3>
						<p>Mitchell, T., Hyde, J., Tew, P., Glowacki, D.R., 2014. danceroom Spectroscopy: At the Frontiers of Physics, Performance, Interactive Art and Technology. Leonardo 49, 138–147. https://doi.org/10.1162/LEON_a_00924</p>
						<p>Bennett, A., 2002. Interactive Aesthetics. Design Issues 18, 62–69. https://doi.org/10.1162/074793602320223307</p>
						<p>de Bérigny, C., Gough, P., Faleh, M., Woolsey, E., 2014. Tangible User Interface Design for Climate Change Education in Interactive Installation Art. Leonardo 47, 451–456. https://doi.org/10.1162/LEON_a_00710</p>
						<p>Wong, C.-O., Jung, K., Yoon, J., 2009. Interactive Art: The Art That Communicates. Leonardo 42, 180–181. https://doi.org/10.1162/leon.2009.42.2.180</p>
						<p>Stern, N., 2011. The Implicit Body as Performance: Analyzing Interactive Art. Leonardo 44, 233–238. https://doi.org/10.1162/LEON_a_00168</p>
						<p>EEG (Electroencephalogram): Purpose, Procedure, and Risks. https://www.healthline.com/health/eeg</p>
						<p>Brain Factory, 2016. MOBEN. URL https://benayoun.com/moben/2016/03/05/brain-factory/ (accessed 7.15.20).</p>
						<p>(PDF) Human Specificity and Recent Science: Communication, Language, Culture [WWW Document], n.d. . ResearchGate. URL
							https://www.researchgate.net/publication/279416161_Human_Specificity_and_Recent_Science_Communication_Language_Culture (accessed 9.13.20).</p>
						<p>Eunoia [WWW Document], n.d. Lisa Park. URL https://www.thelisapark.com/work/eunoia (accessed 7.15.20).</p>
						<p>solaris - ::vtol:: [WWW Document], n.d. URL https://vtol.cc/filter/works/solaris (accessed 7.15.20).</p>
						<p>Artificial Intelligence, All Too Human, 2017. MOBEN. URL https://benayoun.com/moben/2017/08/29/artificial-intelligence-all-too-human/ (accessed 7.15.20).</p>
						<p>Marshall, M., McLuhan, M., 2003. Understanding Media: The Extensions of Man. McGraw-Hill.</p>
						<p>Kotchoubey, B., 2018. Human Consciousness: Where Is It From and What Is It for. Front Psychol 9. https://doi.org/10.3389/fpsyg.2018.00567</p>
						<p>Harvard May Have Pinpointed the Source of Human Consciousness [WWW Document], n.d. Futurism. URL https://futurism.com/harvard-may-have-pinpointed-the-source-of-human-consciousness (accessed 11.3.20).</p>
						<p>Artificial Intelligence, All Too Human, 2017. . MOBEN. URL https://benayoun.com/moben/2017/08/29/artificial-intelligence-all-too-human/ (accessed 9.5.20).</p>
						<p>Bainter, A., 2019. Introduction to Generative Music [WWW Document]. Medium. URL https://medium.com/@metalex9/introduction-to-generative-music-91e00e4dba11 (accessed 7.26.20).</p>
						<p>A. Brouse, "The Interharmonium: An Investigation into Networked Musical Applications and Brainwaves," M.A. dissertation (McGill University, 2001). </p>
						<p>G. Kramer, ed., Auditory Display: Sonification, Audification, and Auditory Interfaces (Reading, MA: Addison-Wesley, 1994). </p>
						<p>Marz, M.B., n.d. Interharmonics: What They Are, Where They Come From and What They Do 8.</p>
						<p>Cycling ’74 [WWW Document], n.d. URL https://cycling74.com/ (accessed 7.31.20).</p>
						<p>Dynamic Tutorial 3: Distortion</p>
						<p>Wekinator | Software for real-time, interactive machine learning, n.d. URL http://www.wekinator.org/ (accessed 9.24.20).</p>
						<p>Introduction to OSC | opensoundcontrol.org [WWW Document], n.d. URL http://opensoundcontrol.org/introduction-osc (accessed 8.2.20).</p>
						<p>Stephen, P.S., 1965. Low viscosity magnetic fluid obtained by the colloidal suspension of magnetic particles. US3215572A.</p>
						<div class="clear"></div>
						<div class="line"></div>

					</div>
				</div>
			</div><!-- .postcontent end -->
		</section><!-- #content end -->


		<!-- Footer
		============================================= -->
		<footer id="footer" class="dark">
			<!-- Copyrights
			============================================= -->
			<div id="copyrights">

				<div class="container clearfix">

					<div class="col_half">
						© Copyright 2020. All Rights Reserved. ShuaiMXu | Made with <i class="fa fa-heart heart"></i> by <a href="https://shuaimxu.com/"> Shuai XU<br>
							<div class="copyright-links"><a href="#">Terms of Use</a> / <a href="#">Privacy Policy</a></div>
					</div>

					<div class="col_half col_last tright">
						<div class="fright clearfix">
							<a href="https://www.facebook.com/xu.shuai.925" class="social-icon si-small si-borderless si-facebook">
								<i class="icon-facebook"></i>
								<i class="icon-facebook"></i>
							</a>


							<a href="https://github.com/ShuaiMXu" class="social-icon si-small si-borderless si-github">
								<i class="icon-github"></i>
								<i class="icon-github"></i>
							</a>

							<a href="https://www.instagram.com/shuaimxu/?hl=en" class="social-icon si-small si-borderless si-instagram">
								<i class="icon-instagram"></i>
								<i class="icon-instagram"></i>
							</a>
						</div>

						<div class="clear"></div>

						<i class="icon-envelope2"></i> xushuai2018@foxmail.com <span class="middot">&middot;</span> <i class="icon-headphones"></i> +44 7419818350 <span class="middot">&middot;</span> <i class="icon-skype2"></i> Shuai XU
					</div>

				</div>

			</div><!-- #copyrights end -->

		</footer><!-- #footer end -->

	</div><!-- #wrapper end -->

	<!-- Go To Top
		============================================= -->
	<div id="gotoTop" class="icon-angle-up"></div>

	<!-- External JavaScripts
		============================================= -->
	<script src="../assets/js/jquery.js"></script>
	<script src="../assets/js/plugins.js"></script>

	<!-- Footer Scripts
		============================================= -->
	<script src="../assets/js/functions.js"></script>

</body>

</html>